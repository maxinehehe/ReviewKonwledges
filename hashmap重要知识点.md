# hashmap的底层数据实现 (java 1.7)

参考 : [java 1.7 hashmap源码详细解释](https://blog.csdn.net/carson_ho/article/details/79373026)

```
我们都知道有序数组存储数据，对数据的索引效率都很高，但是插入和删除就会有性能瓶颈（回忆ArrayList），

链表存储数据，要一次比较元素来检索出数据，所以索引效率低，但是插入和删除效率高（回忆LinkedList），

两者取长补短就产生了哈希散列这种存储方式，也就是HashMap的存储逻辑.
```

## 那么负载因子 **为什么会影响HashMap性能**

```
负载因子表示一个散列表的空间的使用程度，有这样一个公式：initailCapacity*loadFactor=HashMap的容量。

所以负载因子越大则散列表的装填程度越高，也就是能容纳更多的元素，元素多了，链表大了，所以此时索引效率就会降低。

反之，负载因子越小则链表中的数据量就越稀疏，此时会对空间造成浪费，但是此时索引效率高
```

## **如何科学设置 initailCapacity,loadFactor的值**

```
HashMap有三个构造函数，可以选用无参构造函数，不进行设置。默认值分别是16和0.75.

官方的建议是initailCapacity设置成2的n次幂，laodFactor根据业务需求，如果迭代性能不是很重要，可以设置大一下。
```

### 为什么initailCapacity要设置成2的n次幂，（扩容为什么也要是2的n次幂？）

```

```

### hashmap中默认的数组大小是多少，查看源代码可以得知是16，为什么是16，而不是15，也不是20呢？

```
看到上面annegu的解释之后我们就清楚了吧，显然是因为16是2的整数次幂的原因，在小数据量的情况下16比15和20更能减少key之间的碰撞，而加快查询的效率。
在存储大容量数据的时候，最好预先指定hashmap的size为2的整数次幂次方。就算不指定的话，也会以大于且最接近指定值大小的2次幂来初始化的
代码实现：
// Find a power of 2 >= initialCapacity  
        int capacity = 1;  
        while (capacity < initialCapacity)   
            capacity <<= 1;  
            // 其中 << 表示相当于 2的多少次方。
```

## 为什么不直接采用经过hashCode（）处理的哈希码 作为 存储数组table的下标位置？

```
1、计算哈希码：
		h = key.hashCode()
2、二次处理哈希码：
		1.7 扰动处理 = 4次位运算 + 5次异或运算
		1.8 扰动处理 = 1次位运算 + 1次异或运算
3、最终计算存储的数组位置：
		h & (length - 1)
```

```
也就是为什么要像上面那么麻烦？
答：> 首先需要记住一个核心思想：
	所有处理的根本目的，都是为了提高 存储key-value的数组下标位置 的随机性 & 分布均匀性，尽量避免出现hash值冲突。即：对于不同key，存储的数组下标位置要尽可能不一样。
	：容易出现 哈希码 与 数组大小范围不匹配的情况，即 计算出来的哈希码可能 不在数组大小范围内，从而导致无法匹配存储位置
```

## 为什么采用 哈希码 与运算(&) （数组长度-1） 计算数组下标？

> h & (length - 1)?

```
	根据HashMap的容量大小（数组长度），按需取 哈希码一定数量的低位 作为存储的数组下标位置，从而 解决 “哈希码与数组大小范围不匹配” 的问题.
	另外，h & (length  - 1) 也就是取余操作 h % length, 比取余效率高。
```

## 为什么在计算数组下标前，需对哈希码进行二次处理：扰动处理？

```
加大哈希码低位的随机性，使得分布更均匀，从而提高对应数组存储下标位置的随机性 & 均匀性，最终减少Hash冲突
```



